{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Flip the image horizontally for a later selfie-view display\n",
    "    # Also convert the color space from BGR to RGB\n",
    "    image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # To improve performance\n",
    "    image.flags.writeable = False\n",
    "    \n",
    "    # Get the result\n",
    "    results = face_mesh.process(image)\n",
    "    \n",
    "    # To improve performance\n",
    "    image.flags.writeable = True\n",
    "    \n",
    "    # Convert the color space from RGB to BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    img_h, img_w = image.shape[0], image.shape[1]\n",
    "    face_3d = []\n",
    "    face_2d = []\n",
    "    \n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            for idx, lm in enumerate(face_landmarks.landmark):\n",
    "                # Q : 아래 IDX 번호가 의미하는 바? (위치?)\n",
    "                if idx == 33 or idx == 263 or idx == 1 or idx == 61 or idx == 291 or idx == 199:\n",
    "                    x, y = int(lm.x * img_w), int(lm.y * img_h)\n",
    "\n",
    "                    # Get the 2D Coordinates\n",
    "                    face_2d.append([x, y])\n",
    "\n",
    "                    # Get the 3D Coordinates\n",
    "                    face_3d.append([x, y, lm.z])       \n",
    "            \n",
    "            # Convert it to the NumPy array\n",
    "            face_2d = np.array(face_2d, dtype=np.float64)\n",
    "\n",
    "            # Convert it to the NumPy array\n",
    "            face_3d = np.array(face_3d, dtype=np.float64)\n",
    "\n",
    "            # The camera matrix\n",
    "            focal_length = 1 * img_w\n",
    "\n",
    "            cam_matrix = np.array([ [focal_length, 0, img_h / 2],\n",
    "                                    [0, focal_length, img_w / 2],\n",
    "                                    [0, 0, 1]])\n",
    "\n",
    "            # The distortion parameters\n",
    "            dist_matrix = np.zeros((4, 1), dtype=np.float64)\n",
    "\n",
    "            # Solve PnP\n",
    "            suc, rot_vec, trans_vec = cv2.solvePnP(face_3d, face_2d, cam_matrix, dist_matrix)\n",
    "\n",
    "            # Get rotational matrix\n",
    "            rmat = cv2.Rodrigues(rot_vec)[0]\n",
    "\n",
    "            # Get angles\n",
    "            angles = cv2.RQDecomp3x3(rmat)[0]\n",
    "\n",
    "            # Get the y rotation degree\n",
    "            x = angles[0] * 360\n",
    "            y = angles[1] * 360\n",
    "\n",
    "            # See where the user's head tilting\n",
    "            if y < -5:\n",
    "                text_1 = f\"looking left {round(y,1)}\"\n",
    "            elif y > 5:\n",
    "                text_1 = f\"looking right {round(y,1)}\"\n",
    "            else:\n",
    "                text_1 = f\"looking forward.\"\n",
    "\n",
    "            if x < -3:\n",
    "                text_2 = f\"looking down {round(x,1)}\"\n",
    "            elif x > 5:\n",
    "                text_2 = f\"looking up {round(x,1)}\"\n",
    "            else:\n",
    "                text_2 = \" \"\n",
    "\n",
    "            text = text_1 + text_2\n",
    "\n",
    "            # Add the text on the image\n",
    "            cv2.putText(image, text, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 2)\n",
    "            cv2.putText(image, \"x: \" + str(np.round(x,2)), (1000, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.putText(image, \"y: \" + str(np.round(y,2)), (1000, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "\n",
    "        end = time.time()\n",
    "        totalTime = end - start\n",
    "\n",
    "        fps = 1 / totalTime\n",
    "\n",
    "        cv2.putText(image, f'FPS: {int(fps)}', (20,650), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 2)\n",
    "\n",
    "    cv2.imshow('Head Pose Estimation', image)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8",
   "language": "python",
   "name": "yolov8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
